{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset to be uploaded to ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before uploading the data to ElasticSearch, there must be performed a transformation on the data in order to give it a format that is suitable for being aggregated, queried and analyzed. We eliminate the fields that are not going to be used, such as the city, the food categories, the food names, the label \"IsFood\", the users id, the place field and the lang. Other fields such as \"created_at\" will be transformed to keep only the hour of the day in which the tweet was created, and the coordinates field will be transformed in two different fields with the latitude and the longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PruebaSVM.csv')\n",
    "df\n",
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1','Unnamed: 0.1.1.1','Unnamed: 0.1.1.1.1','Unnamed: 0.1.1.1.1.1','Unnamed: 0.1.1.1.1.1.1','Unnamed: 0.1.1.1.1.1.1.1','Unnamed: 0.1.1.1.1.1.1.1','Unnamed: 0.1.1.1.1.1.1.1.1','City','Categor√≠as','Foods','IsFood',\"id\",\"id_str\",\"place\",\"lang\"], axis=1, inplace=True)\n",
    "df.to_csv('data.csv')\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_at = []\n",
    "for i in df['created_at']:\n",
    "    created_at.append(int(i.split(':')[0]))\n",
    "df['created_at']=created_at\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Calorias == 0] = None\n",
    "df.drop(df[df.Calorias.isna()].index,inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = []\n",
    "long = []\n",
    "for i in df['Coordinates']:\n",
    "    long.append(float(i.split(', ')[0].replace('(','')))\n",
    "    lat.append(float(i.split(', ')[1].replace(')','')))\n",
    "df['lat']=lat\n",
    "df['long']=long\n",
    "df.drop(['Coordinates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hidratos'] = df['Hidratos de Carbono']\n",
    "df.drop(['Hidratos de Carbono'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('data.csv', 'r')\n",
    "jsonfile = open('data.json', 'w')\n",
    "\n",
    "fieldnames = (\"Index\",\"Calorias\",\"Colesterol\",\"ComunidadAutonoma\",\"Country\",\"Fibra\",\"Gender\",\"Grasas\",\"Proteinas\",\"created_at\",\"sentiment\",\"text\",\"user\",\"day\",\"Health\",\"lat\",\"long\",\"Hidratos\")\n",
    "reader = csv.DictReader( csvfile, fieldnames)\n",
    "for row in reader:\n",
    "    json.dump(row, jsonfile)\n",
    "    jsonfile.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
